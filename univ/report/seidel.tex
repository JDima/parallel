%!TEX root = parallel.tex
\section{Метод Гаусса-Зейделя}
\subsection{Описание}
Пусть имеется система:
\begin{equation*}
  A \, \vec{x} \, = \, \vec{b}
\end{equation*}
Построим итеративную процедуру, которая на каждом шаге будет вычислять решение:
\begin{equation*}
  x_i^{k + 1} = \sum_{j=1}^{i - 1} c_{ij}x_{j}^{k+1} + \sum_{j=i}^{n} c_{ij}x_{j}^{k} + d_i
\end{equation*}
где
\begin{equation*}
  c_{ij} =
  \left\{
  \begin{matrix}
  - \frac{a_{ij}}{a_{ii}}, & j \neq i, \\
  0, & j = i.
  \end{matrix} \right. \, \,
  d_i = \frac{b_i}{a_{ii}}
\end{equation*}
Основное отличие от метода Якоби заключается в том, что новые значения компонент $\vec{x}$ используется
для вычисления последующих компонент $\vec{x}$.

Предлагается для каждого процесса вычислять новые значения координат вектора. После объединить полученные значения и вычислить невязку.

\subsection{Результаты}
Было произведены сравнения работы для различных СЛАУ отдельно OpenMP и MPI. Ниже в таблице приведены результаты.

\begin{table}[!h]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{N} & \multicolumn{1}{c|}{100} & 500    & \multicolumn{1}{c|}{1000} & \multicolumn{1}{c|}{2000} & 4000  \\ \hline
MPI                     & 0.001                    & 0.0016 & 0.0034                    & 0.007                     & 0.019 \\ \hline
OpenMP                  & 0.0002                   & 0.0006 & 0.0009                    & 0.002                     & 0.018 \\ \hline
\end{tabular}
\caption{Результаты запусков решешния СЛАУ}
\end{table}

Из таблицы следует, что реализация с помощью OpenMP быстрее.
